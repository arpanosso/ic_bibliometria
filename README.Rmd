---
output: github_document
---


<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  error = FALSE,
  message = FALSE,
  # eval = FALSE,
  comment = "#>"
)
```


## TCC - Maria Eduarda - Bibliometria

### Carregando Pacotes

```{r}
library(tidyverse)
```

###  Carregando a Base
```{r}
base_wos <- readxl::read_xlsx("data_raw/wob_extraidos.xlsx") |> 
  janitor::clean_names() |> 
  mutate(
    abstract_1 = str_remove_all(abstract_1, "\r"),
    abstract_2 = str_remove_all(abstract_2, "\r"),
    research_areas   = str_replace_all(research_areas, "\n", " "),
    research_areas   = str_replace_all(research_areas, "  ", " "),
    titulo = str_remove_all(titulo, "\r|™"),
    autor = str_to_title(autor),
    nome_base = "wos"
  ) |> 
  rename( resumo = abstract_1)
base_me <- readxl::read_xlsx("data_raw/Arquivos Extraídos/search_result--1968698800-csv/search_result--1968698800-csv.xlsx") |> janitor::clean_names() |> 
  rename(autor = autor_a,ano = ano_de_defesa,
         instituicao = instituicao_de_defesa,
         pais = pais_da_instituicao_de_defesa) |> 
  mutate(pais = ifelse(pais == "Não informado pela instituição","Brasil",pais),
         assuntos_em_portugues = str_remove_all(assuntos_em_portugues,"\\|"),
         assuntos_em_ingles = str_remove_all(assuntos_em_portugues,"\\|"),
         autor = str_to_title(autor),
         nome_base = "bdtd")
```

```{r}
glimpse(base_me) 
```

## Juntando  e tratando as Bases

```{r}
base_completa <- rbind(base_wos |> 
  select(nome_base, autor, ano, titulo, instituicao, resumo, pais),
base_me |> 
  select(nome_base, autor, ano, titulo, instituicao, resumo, pais)
) |> 
  distinct() |> 
  mutate(
    pais = str_replace(pais, "BR|Brasil|brasil|brazil","Brazil"),
    ano = as.numeric(ano)
  )
```

### Estatística Descritiva

#### Número de Documentos por Ano
```{r}
base_completa |> 
  group_by(ano) |> 
  count() |> 
  ggplot(aes(ano, n)) +
  geom_col(color="black", fill="gray") +
  labs(x="Ano", y = "Número de Documentos") +
  theme_minimal()
```

#### Número de Documentos por Ano / País
```{r}
base_completa |> 
  group_by(ano,pais,nome_base) |> 
  count() |> 
  ggplot(aes(ano, n, fill=pais)) +
  geom_col(color="black") +
  labs(x="Ano", y = "Número de Documentos") +
  theme_minimal() +
  facet_wrap(~nome_base)
```

#### Soma do número de documentos para o período todo (2020 a 2025)

```{r}
base_completa |> 
  group_by(pais,nome_base) |> 
  count() |> 
  ungroup() |> 
  mutate(pais = fct_reorder(pais,n)) |> 
  ggplot(aes(y=pais, x=n)) +
  geom_col(color="black",fill="aquamarine4") +
  labs(x="Soma dos Documentos", y = "País") +
  theme_minimal() +
  facet_wrap(~nome_base)
```


##### Exemplo
```{r}
base_completa |> 
  mutate(
    ia_count = as.numeric(str_detect(
      str_to_lower(resumo), 
      "(artificial\\s+inteligente|\\bai\\b|environmental impact)"))
  ) |> group_by(ano) |> 
  summarise(
    n = sum(ia_count),
    .groups = "drop"
  ) |> 
  ggplot(aes(x=ano, y=n)) + 
  geom_point() +
  geom_line() +
  theme_bw()
```

#### 1

```{r}
library(quanteda)
library(quanteda.textstats)
library(igraph)

vetor_de_resumos <- base_completa |> 
  slice(1:10) |> 
  pull(resumo)
corp <- corpus(vetor_de_resumos)
toks <- tokens(corp, remove_punct = TRUE, remove_numbers = TRUE)
toks <- tokens_remove(toks, stopwords("en"))

fcmat <- fcm(toks, context = "window", tri = FALSE)
g <- graph_from_adjacency_matrix(fcmat, weighted = TRUE, mode = "undirected")
plot(g)
```



